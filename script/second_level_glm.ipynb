{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- SECOND LEVEL ANALYSIS ------------\n",
    "# ---------------- Default HRF ----------------\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "import nilearn \n",
    "import itertools\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "from numpy import savetxt\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.image import get_data, math_img\n",
    "from nilearn import plotting, image, datasets\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from nilearn.datasets import fetch_localizer_contrasts\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.glm.second_level import make_second_level_design_matrix\n",
    "#from nilearn.glm.second_level import non_parametric_inference\n",
    "#from scipy.stats import norm\n",
    "\n",
    "# Init variables\n",
    "init_folder='/home/traaffneu/margal/code/multirat_se/script/'\n",
    "analysis_folder='/project/4180000.19/multirat_stim/scratch/rabies_test/first_level/'\n",
    "z_scores_path = \"/project/4180000.19/multirat_stim/scratch/rabies_test/first_level/z_score/\"\n",
    "beta_path = \"/project/4180000.19/multirat_stim/scratch/rabies_test/first_level/beta_estimates/\"\n",
    "\n",
    "# Data path\n",
    "template_path ='/groupshare/traaffneu/preclinimg/templates/SIGMA_Wistar_Rat_Brain_TemplatesAndAtlases_Version1.1/SIGMA_Rat_Anatomical_Imaging/SIGMA_Rat_Anatomical_InVivo_Template/SIGMA_InVivo_Brain_Template.nii'\n",
    "metadata_path = '/home/traaffneu/margal/code/multirat_se/script/table/metadata_stand.tsv'\n",
    "\n",
    "# Output path\n",
    "output_dir = '/project/4180000.19/multirat_stim/scratch/rabies_test/second_level/'\n",
    "glover_dir =  os.path.join(output_dir, 'glover/')\n",
    "spm_dir = os.path.join(output_dir, 'spm/')\n",
    "\n",
    "glover_image_dir = os.path.join(glover_dir, 'image/')\n",
    "glover_beta_dir = os.path.join(glover_dir, 'beta_estimates/')\n",
    "glover_z_score_dir = os.path.join(glover_dir, 'z_score/')\n",
    "glover_p_value_dir = os.path.join(glover_dir, 'p_value/')\n",
    "glover_clusters_dir = os.path.join(glover_dir, 'clusters/')\n",
    "\n",
    "spm_image_dir = os.path.join(spm_dir, 'image/')\n",
    "spm_beta_dir = os.path.join(spm_dir, 'beta_estimates/')\n",
    "spm_z_score_dir = os.path.join(spm_dir, 'z_score/')\n",
    "spm_p_value_dir = os.path.join(spm_dir, 'p_value/')\n",
    "spm_clusters_dir = os.path.join(spm_dir, 'clusters/')\n",
    "\n",
    "if not os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "if not os.path.exists(glover_dir): os.makedirs(glover_dir)\n",
    "if not os.path.exists(spm_dir): os.makedirs(spm_dir)\n",
    "\n",
    "if not os.path.exists(glover_image_dir): os.makedirs(glover_image_dir)\n",
    "if not os.path.exists(glover_beta_dir): os.makedirs(glover_beta_dir)\n",
    "if not os.path.exists(glover_z_score_dir): os.makedirs(glover_z_score_dir)\n",
    "if not os.path.exists(glover_p_value_dir): os.makedirs(glover_p_value_dir)\n",
    "if not os.path.exists(glover_clusters_dir): os.makedirs(glover_clusters_dir)\n",
    "if not os.path.exists(spm_image_dir): os.makedirs(spm_image_dir)\n",
    "if not os.path.exists(spm_beta_dir): os.makedirs(spm_beta_dir)\n",
    "if not os.path.exists(spm_z_score_dir): os.makedirs(spm_z_score_dir)\n",
    "if not os.path.exists(spm_p_value_dir): os.makedirs(spm_p_value_dir)\n",
    "if not os.path.exists(spm_clusters_dir): os.makedirs(spm_clusters_dir)\n",
    "\n",
    "df = pd.read_csv(metadata_path, sep='\\t')\n",
    "df = df.loc[(df['exclude'] != 'yes')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Input data ---\n",
    "\n",
    "\"\"\" Define hrf model used for the first analysis\n",
    "    Options : \n",
    "    ---------\n",
    "    spm\n",
    "    glover\n",
    "\"\"\"\n",
    "hrf_function = 'glover'\n",
    "#hrf_function = 'spm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First level analysis used: glover\n",
      "ID: 02005\n",
      "number of subjects: 10\n"
     ]
    }
   ],
   "source": [
    "# ---------- SECOND LEVEL ANALYSIS ------------\n",
    "# ---------------- Default HRF ----------------\n",
    "\n",
    "print('First level analysis used:', hrf_function)\n",
    "\n",
    "for index in range(5, 6):\n",
    "    \n",
    "    ID = \"0\"+str(2000+index)\n",
    "    print(\"ID:\", ID)\n",
    "    \n",
    "    #if ID == \"02010\":\n",
    "     #   continue\n",
    " \n",
    "    # -- Load data --\n",
    "    if hrf_function == 'glover':\n",
    "        dataset = glob.glob(analysis_folder+'glover/beta_estimates/beta_sub-{}??_ses-1.nii.gz'.format(ID))\n",
    "    elif hrf_function == 'spm':\n",
    "        dataset = glob.glob(analysis_folder+'spm/beta_estimates/beta_sub-{}??_ses-1.nii.gz'.format(ID))\n",
    "    else:\n",
    "        print('No file to be saved. Check that hrf_function is well defined.')\n",
    "    \n",
    "    n_subject = len(dataset)                                                           \n",
    "    print(\"number of subjects:\", n_subject)\n",
    "\n",
    "    second_level_input = dataset\n",
    "    design_matrix = pd.DataFrame([1] * len(second_level_input), \n",
    "                                columns=[\"intercept\"])\n",
    "\n",
    "\n",
    "    # --- Specify the model and fit it --- \n",
    "    second_level_model = SecondLevelModel(smoothing_fwhm=0.1,\n",
    "                                          minimize_memory=False)        #if want to get residuals?\n",
    "\n",
    "    second_level_model = second_level_model.fit(second_level_input,\n",
    "                                                design_matrix=design_matrix)\n",
    "\n",
    "\n",
    "    # --- Estimate the contrast --- \n",
    "    second_stat_map = second_level_model.compute_contrast(second_level_contrast='intercept', output_type='all') \n",
    "\n",
    "    # nib.save(second_stat_map['z_score'], z_score_dir+'z_score_dataset-{}.nii.gz'.format(ID))          #save z_score map\n",
    "    # nib.save(second_stat_map['effect_size'], beta_dir+'beta_dataset-{}.nii.gz'.format(ID))            #save the beta estimates\n",
    "    # nib.save(second_stat_map['p_value'], p_value_dir+'p_value_dataset-{}.nii.gz'.format(ID))          #save the p_value\n",
    "\n",
    "    p_val = 0.05\n",
    "    plot_stat = plotting.plot_stat_map(second_stat_map['z_score'],\n",
    "                                        bg_img = template_path,\n",
    "                                        threshold = 1,              #threshold p=p_val=0.05 uncorrected -> reduces false negative levels\n",
    "                                        cut_coords= (0 ,0, 5.5),        \n",
    "                                        display_mode='ortho',\n",
    "                                        draw_cross=True,\n",
    "                                        colorbar=True,\n",
    "                                        vmax = 5, \n",
    "                                        title=\"Dataset {}\".format(ID))\n",
    "    \n",
    "    #-- Save outputs --  \n",
    "    if hrf_function == 'glover':\n",
    "        nib.save(second_stat_map['z_score'], glover_z_score_dir+'z_score_dataset-{}.nii.gz'.format(ID))          #save z_score map\n",
    "        nib.save(second_stat_map['effect_size'], glover_beta_dir+'beta_dataset-{}.nii.gz'.format(ID))            #save the beta estimates\n",
    "        nib.save(second_stat_map['p_value'], glover_p_value_dir+'p_value_dataset-{}.nii.gz'.format(ID))          #save the p_value\n",
    "        plt.savefig(glover_image_dir+'stat_map_dataset-{}_z_score.png'.format(ID)) \n",
    "\n",
    "    elif hrf_function == 'spm':\n",
    "        #nib.save(second_stat_map['z_score'], spm_z_score_dir+'z_score_dataset-{}.nii.gz'.format(ID))          #save z_score map\n",
    "        #nib.save(second_stat_map['effect_size'], spm_beta_dir+'beta_dataset-{}.nii.gz'.format(ID))            #save the beta estimates\n",
    "        #nib.save(second_stat_map['p_value'], spm_p_value_dir+'p_value_dataset-{}.nii.gz'.format(ID))          #save the p_value\n",
    "        plt.savefig(spm_image_dir+'stat_map_dataset-{}_z_score.png'.format(ID)) \n",
    "\n",
    "    else:\n",
    "        print('No file to be saved. Check that hrf_function is well defined.')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_stat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreporting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_clusters_table\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnilearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmaskers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NiftiSpheresMasker\n\u001b[0;32m----> 6\u001b[0m colorbar \u001b[38;5;241m=\u001b[39m \u001b[43mplot_stat\u001b[49m\u001b[38;5;241m.\u001b[39m_cbar                      \u001b[38;5;66;03m# get the statistical scale from the plot\u001b[39;00m\n\u001b[1;32m      7\u001b[0m vmin, vmax \u001b[38;5;241m=\u001b[39m colorbar\u001b[38;5;241m.\u001b[39mmappable\u001b[38;5;241m.\u001b[39mget_clim()\n\u001b[1;32m      8\u001b[0m set_tresh \u001b[38;5;241m=\u001b[39m vmax \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m                            \u001b[38;5;66;03m# get the stat_threshold for cluster, depending on the dataset\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_stat' is not defined"
     ]
    }
   ],
   "source": [
    "    #-- Extract clusters -- https://nilearn.github.io/dev/auto_examples/04_glm_first_level/plot_predictions_residuals.html#sphx-glr-auto-examples-04-glm-first-level-plot-predictions-residuals-py\n",
    "\n",
    "    from nilearn.reporting import get_clusters_table\n",
    "    from nilearn.maskers import NiftiSpheresMasker\n",
    "\n",
    "    colorbar = plot_stat._cbar                      # get the statistical scale from the plot\n",
    "    vmin, vmax = colorbar.mappable.get_clim()\n",
    "    set_tresh = vmax / 2                            # get the stat_threshold for cluster, depending on the dataset\n",
    "    print(\"cluster treshold: \", set_tresh)\n",
    "    \n",
    "    table = get_clusters_table(second_stat_map['z_score'],\n",
    "                            stat_threshold=set_tresh,\n",
    "                            cluster_threshold=40)\n",
    "\n",
    "\n",
    "    table.set_index(\"Cluster ID\", drop=True)\n",
    "    print('Cluster table: ok')\n",
    "\n",
    "    coords = table.loc[range(0, len(table)), ['X', 'Y', 'Z']].values                     # get the clusters' x, y, and z coordinates (if want the 4 largest, range(0, 4)\n",
    "    coords = coords.reshape(-1, 3)                                                       # reshape in 3D\n",
    "    print(\"(nb clusters, dimension):\", coords.shape)                                     # output = (number_clusters, 3)\n",
    "    \n",
    "    timeseries_masker = NiftiSpheresMasker(coords, radius=1)                             # extracts time series data from a set of spherical regions of interest (ROIs) in a 3D fMRI image\n",
    "    \n",
    "    fmri_img = image.concat_imgs(dataset)\n",
    "\n",
    "    #real_timeseries = timeseries_masker.fit_transform(fmri_img)                          # applies the masker to an fMRI image, outputs 2D numpy array. Returns signal for each sphere, shape: (number of scans, number of spheres)\n",
    "    #savetxt(clusters_dir+'cluster_timeseries_dataset-0{}.csv'.format(ID), real_timeseries, delimiter=',')       #save as .csv file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster treshold:  1.4046857357025146\n",
      "Cluster table: ok\n",
      "(nb clusters, dimension): (3, 3)\n"
     ]
    }
   ],
   "source": [
    "    #-- Extract clusters -- \n",
    "    # https://nilearn.github.io/dev/auto_examples/04_glm_first_level/plot_predictions_residuals.html#sphx-glr-auto-examples-04-glm-first-level-plot-predictions-residuals-py\n",
    "\n",
    "    from nilearn.reporting import get_clusters_table\n",
    "    from nilearn.maskers import NiftiSpheresMasker\n",
    "\n",
    "    colorbar = plot_stat._cbar                      # get the statistical scale from the plot\n",
    "    vmin, vmax = colorbar.mappable.get_clim()\n",
    "    set_tresh = vmax / 2                            # get the stat_threshold for cluster, depending on the dataset\n",
    "    print(\"cluster treshold: \", set_tresh)\n",
    "    \n",
    "    table = get_clusters_table(second_stat_map['z_score'],\n",
    "                            stat_threshold=set_tresh,\n",
    "                            cluster_threshold=40)\n",
    "\n",
    "\n",
    "    table.set_index(\"Cluster ID\", drop=True)\n",
    "    print('Cluster table: ok')\n",
    "\n",
    "    coords = table.loc[range(0, len(table)), ['X', 'Y', 'Z']].values                     # get the clusters' x, y, and z coordinates (if want the 4 largest, range(0, 4)\n",
    "    coords = coords.reshape(-1, 3)                                                       # reshape in 3D\n",
    "    masker = NiftiSpheresMasker(coords, radius=1)                                        # extracts time series data from a set of spherical regions of interest (ROIs) in a 3D fMRI image\n",
    "\n",
    "    print(\"(nb clusters, dimension):\", coords.shape)                                     # output = (number_clusters, 3)\n",
    "    \n",
    "    fmri_img = image.concat_imgs(dataset)                                                 \n",
    "    real_timeseries = masker.fit_transform(fmri_img)                                     # applies the masker to an fMRI image, outputs 2D numpy array\n",
    "    \n",
    "    savetxt(clusters_dir+'cluster_dataset-0{}.csv'.format(ID), real_timeseries, delimiter=',')       #save as .csv file\n",
    "\n",
    "#-----\n",
    "    # predicted_timeseries = masker.fit_transform(second_level_model.predicted[0])\n",
    "    #resid_cluster = masker.fit_transform(second_level_model.residuals[0])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "   Cluster ID         X         Y         Z  Peak Stat  Cluster Size (mm3)\n",
      "0           1  5.860001 -1.309999 -2.265000   2.736944                   2\n",
      "1           2  5.260001  0.190001  7.635001   2.334762                   1\n",
      "2           3 -7.039999 -1.309999  7.635001   2.032514                   1\n"
     ]
    }
   ],
   "source": [
    "print(coords.shape)\n",
    "print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
