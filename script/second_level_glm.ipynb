{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img align=\"right\" src=\"https://nilearn.github.io/dev-days-2020/assets/images/nilearn-logo.png\" alt=\"image\" width=\"250\" />\n",
    "</p>\n",
    "\n",
    "<h1 align=\"center\">MultiRat Sensory-Evoked analysis code</h1>\n",
    "\n",
    "<p align=\"center\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<i>Marie E Galteau, 2023</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Level Analysis - **Default** Hemodynamic Response Function\n",
    "\n",
    "The present jupyter notebook contains the code to reproduce the second level analysis. Select the hemodynamic response functions used during the first level analysis: spm or glover. It enables to fetch the files in the corresponding directories. \n",
    "\n",
    "Follow the code step-wise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import os\n",
    "import glob\n",
    "import nilearn \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "from numpy import savetxt\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting, image, datasets\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from nilearn.glm.second_level import SecondLevelModel\n",
    "from nilearn.glm.second_level import make_second_level_design_matrix\n",
    "\n",
    "# --- Init variables ---\n",
    "init_folder='/home/traaffneu/margal/code/multirat_se/script/'\n",
    "analysis_folder='/project/4180000.19/multirat_stim/scratch/rabies_test/first_level/'\n",
    "\n",
    "# --- Data path ---\n",
    "template_path ='/groupshare/traaffneu/preclinimg/templates/SIGMA_Wistar_Rat_Brain_TemplatesAndAtlases_Version1.1/SIGMA_Rat_Anatomical_Imaging/SIGMA_Rat_Anatomical_InVivo_Template/SIGMA_InVivo_Brain_Template.nii'\n",
    "metadata_path = '/home/traaffneu/margal/code/multirat_se/script/table/metadata_stand.tsv'\n",
    "df = pd.read_csv(metadata_path, sep='\\t')\n",
    "df = df.loc[(df['exclude'] != 'yes')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select the hemodynamic response function!** \n",
    "\n",
    "To input the corresponding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Select the HRF ---\n",
    "\n",
    "\"\"\" Define hrf model used for the first analysis\n",
    "    Options : \n",
    "    ---------\n",
    "    spm\n",
    "    glover\n",
    "\"\"\"\n",
    "hrf_function = 'glover'\n",
    "#hrf_function = 'spm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hrf_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/project/4180000.19/multirat_stim/scratch/rabies_test/second_level/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m subdirectories \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglover\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspm\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglover\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mhrf_function\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mglover\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m image_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m beta_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta_estimates/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hrf_function' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Output path ---\n",
    "output_dir = '/project/4180000.19/multirat_stim/scratch/rabies_test/second_level/'\n",
    "subdirectories = ['glover', 'spm']\n",
    "\n",
    "base_dir = os.path.join(output_dir, 'glover') if hrf_function == 'glover' else os.path.join(output_dir, 'spm')\n",
    "image_dir = os.path.join(base_dir, 'image/')\n",
    "beta_dir = os.path.join(base_dir, 'beta_estimates/')\n",
    "z_score_dir = os.path.join(base_dir, 'z_score/')\n",
    "p_value_dir = os.path.join(base_dir, 'p_value/')\n",
    "\n",
    "for subdir in subdirectories:\n",
    "    sub_dir = os.path.join(output_dir, subdir)\n",
    "    sub_dir_structure = ['image', 'beta_estimates', 'z_score', 'p_value']\n",
    "    \n",
    "    for sub_subdir in sub_dir_structure:\n",
    "        dir_path = os.path.join(sub_dir, sub_subdir)\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's analyse!\n",
    "\n",
    "1. Load the dataset based on its ID and the HRF function used during first analysis.\n",
    "2. Compute the design matrix and the first level model\n",
    "3. Compute the contrast and plot the statistical maps\n",
    "7. Save ouputs in specific directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First level analysis used: glover\n",
      "ID: 02000\n",
      "number of subjects: 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "A second level model requires a list with at least two first level models or niimgs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m\n\u001b[1;32m     25\u001b[0m design_matrix \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(second_level_input), \n\u001b[1;32m     26\u001b[0m                             columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintercept\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     28\u001b[0m second_level_model \u001b[38;5;241m=\u001b[39m SecondLevelModel(smoothing_fwhm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     29\u001b[0m                                       minimize_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)        \u001b[38;5;66;03m#if want to get residuals?\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m second_level_model \u001b[38;5;241m=\u001b[39m \u001b[43msecond_level_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msecond_level_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdesign_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesign_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# --- Estimate the contrast --- \u001b[39;00m\n\u001b[1;32m     36\u001b[0m second_stat_map \u001b[38;5;241m=\u001b[39m second_level_model\u001b[38;5;241m.\u001b[39mcompute_contrast(second_level_contrast\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintercept\u001b[39m\u001b[38;5;124m'\u001b[39m, output_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nilearn/glm/second_level/second_level.py:481\u001b[0m, in \u001b[0;36mSecondLevelModel.fit\u001b[0;34m(self, second_level_input, confounds, design_matrix)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the second-level :term:`GLM`.\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m1. create design matrix\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    478\u001b[0m \n\u001b[1;32m    479\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# check second_level_input\u001b[39;00m\n\u001b[0;32m--> 481\u001b[0m \u001b[43m_check_second_level_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43msecond_level_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesign_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfounds\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# check confounds\u001b[39;00m\n\u001b[1;32m    486\u001b[0m _check_confounds(confounds)\n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nilearn/glm/second_level/second_level.py:38\u001b[0m, in \u001b[0;36m_check_second_level_input\u001b[0;34m(second_level_input, design_matrix, confounds)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_second_level_input\u001b[39m(\n\u001b[1;32m     35\u001b[0m     second_level_input, design_matrix, confounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     36\u001b[0m ):\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check second_level_input type.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     input_type \u001b[38;5;241m=\u001b[39m \u001b[43m_check_input_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43msecond_level_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     _check_input_as_type(\n\u001b[1;32m     40\u001b[0m         second_level_input,\n\u001b[1;32m     41\u001b[0m         input_type,\n\u001b[1;32m     42\u001b[0m         confounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     43\u001b[0m         design_matrix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nilearn/glm/second_level/second_level.py:54\u001b[0m, in \u001b[0;36m_check_input_type\u001b[0;34m(second_level_input)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnii_object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(second_level_input, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_check_input_type_when_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43msecond_level_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecond_level_input must be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither a pandas DataFrame, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_return_type(second_level_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     62\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nilearn/glm/second_level/second_level.py:75\u001b[0m, in \u001b[0;36m_check_input_type_when_list\u001b[0;34m(second_level_input)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Determine the type of input provided when it is a list.\"\"\"\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(second_level_input) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA second level model requires a list with at\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m least two first level models or niimgs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m     )\n\u001b[1;32m     79\u001b[0m _check_all_elements_of_same_type(second_level_input)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mstr\u001b[39m, Nifti1Image)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m second_level_input):\n",
      "\u001b[0;31mTypeError\u001b[0m: A second level model requires a list with at least two first level models or niimgs"
     ]
    }
   ],
   "source": [
    "# ---------- SECOND LEVEL ANALYSIS ------------\n",
    "# ---------------- Default HRF ----------------\n",
    "\n",
    "print('First level analysis used:', hrf_function)\n",
    "\n",
    "for index in range(0, len(df)):\n",
    "    \n",
    "    # --- Load data ---\n",
    "    ID = \"0\"+str(2000+index)\n",
    "    print(\"ID:\", ID)\n",
    " \n",
    "    if hrf_function == 'glover':\n",
    "        dataset = glob.glob(analysis_folder+'glover/beta_estimates/beta_sub-{}??_ses-1.nii.gz'.format(ID))\n",
    "    elif hrf_function == 'spm':\n",
    "        dataset = glob.glob(analysis_folder+'spm/beta_estimates/beta_sub-{}??_ses-1.nii.gz'.format(ID))\n",
    "    else:\n",
    "        print('No file to be saved. Check that hrf_function is well defined.')\n",
    "    \n",
    "    n_subject = len(dataset)                                                           \n",
    "    print(\"number of subjects:\", n_subject)\n",
    "\n",
    "    second_level_input = dataset\n",
    "    \n",
    "    # --- Design matrix and second-level model ---\n",
    "    design_matrix = pd.DataFrame([1] * len(second_level_input), \n",
    "                                columns=[\"intercept\"])\n",
    " \n",
    "    second_level_model = SecondLevelModel(smoothing_fwhm=0.1,\n",
    "                                          minimize_memory=False)        #if want to get residuals?\n",
    "\n",
    "    second_level_model = second_level_model.fit(second_level_input,\n",
    "                                                design_matrix=design_matrix)\n",
    "\n",
    "\n",
    "    # --- Estimate the contrast --- \n",
    "    second_stat_map = second_level_model.compute_contrast(second_level_contrast='intercept', output_type='all') \n",
    "\n",
    "    p_val = 0.05\n",
    "    plot_stat = plotting.plot_stat_map(second_stat_map['z_score'],\n",
    "                                        bg_img = template_path,\n",
    "                                        threshold = 1,              #threshold p=p_val=0.05 uncorrected -> reduces false negative levels\n",
    "                                        #cut_coords= (0 ,0, 5.5),        \n",
    "                                        display_mode='ortho',\n",
    "                                        draw_cross=True,\n",
    "                                        colorbar=True,\n",
    "                                        vmax = 5, \n",
    "                                        title=\"Dataset {}\".format(ID))\n",
    "    \n",
    "    # --- Save outputs ---  \n",
    "    plt.savefig(image_dir+'stat_map_dataset-{}_z_score.png'.format(ID)) \n",
    "    nib.save(second_stat_map['z_score'], z_score_dir+'z_score_dataset-{}.nii.gz'.format(ID))          \n",
    "    #nib.save(second_stat_map['effect_size'], beta_dir+'beta_dataset-{}.nii.gz'.format(ID))            \n",
    "    #nib.save(second_stat_map['p_value'], p_value_dir+'p_value_dataset-{}.nii.gz'.format(ID))   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
