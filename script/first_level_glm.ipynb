{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nilearn \n",
    "import nibabel as nib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "\n",
    "\n",
    "from nilearn import plotting, image\n",
    "from nilearn.glm.first_level import compute_regressor\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from numpy import savetxt\n",
    "from subprocess import call\n",
    "from subprocess import Popen\n",
    "\n",
    "#Submit job to HPC\n",
    "#subprocess.call(['qsub', '-l', 'procs=1,mem=24gb,walltime=12:00:00 -I'])\n",
    "\n",
    "# Init variables\n",
    "init_folder='/home/traaffneu/margal/code/multirat_se/script/'\n",
    "analysis_folder='/project/4180000.19/multirat_stim/rabies/preprocess'\n",
    "            \n",
    "# Data path\n",
    "template_path ='/groupshare/traaffneu/preclinimg/templates/SIGMA_Wistar_Rat_Brain_TemplatesAndAtlases_Version1.1/SIGMA_Rat_Anatomical_Imaging/SIGMA_Rat_Anatomical_InVivo_Template/SIGMA_InVivo_Brain_Template.nii'\n",
    "metadata_path = '/home/traaffneu/margal/code/multirat_se/script/table/metadata_stand.tsv'\n",
    "\n",
    "# Paths for the directories\n",
    "output_dir = '/project/4180000.19/multirat_stim/rabies_test/first_level_analysis/'\n",
    "matrix_dir = os.path.join(output_dir, 'matrix/')\n",
    "image_dir = os.path.join(output_dir, 'image/')\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "if not os.path.exists(matrix_dir):\n",
    "    os.makedirs(matrix_dir)\n",
    "if not os.path.exists(image_dir):\n",
    "    os.makedirs(image_dir)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(metadata_path, sep='\\t')\n",
    "df = df.loc[(df['exclude'] != 'yes')]\n",
    "\n",
    "print(df['func.sensory.onset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48882169.dccn-l029.dccn.nl\n",
      "200509\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m func_img \u001b[39m=\u001b[39m nib\u001b[39m.\u001b[39mload(subject_path)\n\u001b[1;32m     20\u001b[0m header \u001b[39m=\u001b[39m func_img\u001b[39m.\u001b[39mheader\n\u001b[0;32m---> 23\u001b[0m dimension \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(image\u001b[39m.\u001b[39;49mload_img(subject_path)\u001b[39m.\u001b[39mshape)          \u001b[39m#put in an array; dimension, number of slices, number of volumes \u001b[39;00m\n\u001b[1;32m     24\u001b[0m n_scans \u001b[39m=\u001b[39m dimension[\u001b[39m3\u001b[39m]                                            \u001b[39m#nb volumes\u001b[39;00m\n\u001b[1;32m     25\u001b[0m frame_times \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(n_scans) \u001b[39m*\u001b[39m tr                             \u001b[39m# corresponding frame times\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nilearn/image/image.py:1275\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(img, wildcards, dtype)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_img\u001b[39m(img, wildcards\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1240\u001b[0m     \u001b[39m\"\"\"Load a Niimg-like object from filenames or list of filenames.\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m \n\u001b[1;32m   1242\u001b[0m \u001b[39m    .. versionadded:: 0.2.5\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \n\u001b[1;32m   1274\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1275\u001b[0m     \u001b[39mreturn\u001b[39;00m check_niimg(img, wildcards\u001b[39m=\u001b[39;49mwildcards, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nilearn/_utils/niimg_conversions.py:286\u001b[0m, in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[39mreturn\u001b[39;00m concat_niimgs(niimg, ensure_ndim\u001b[39m=\u001b[39mensure_ndim, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    285\u001b[0m \u001b[39m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m niimg \u001b[39m=\u001b[39m load_niimg(niimg, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m ensure_ndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(niimg\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m \u001b[39mand\u001b[39;00m niimg\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    289\u001b[0m     \u001b[39m# \"squeeze\" the image.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     data \u001b[39m=\u001b[39m _safe_get_data(niimg)\n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nilearn/_utils/niimg.py:137\u001b[0m, in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(niimg, nibabel\u001b[39m.\u001b[39mspatialimages\u001b[39m.\u001b[39mSpatialImage):\n\u001b[1;32m    133\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mData given cannot be loaded because it is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m not compatible with nibabel format:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m                     \u001b[39m+\u001b[39m _repr_niimgs(niimg, shorten\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m--> 137\u001b[0m dtype \u001b[39m=\u001b[39m _get_target_dtype(_get_data(niimg)\u001b[39m.\u001b[39mdtype, dtype)\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[39m# Copyheader and set dtype in header if header exists\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m niimg\u001b[39m.\u001b[39mheader \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nilearn/_utils/niimg.py:26\u001b[0m, in \u001b[0;36m_get_data\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m img\u001b[39m.\u001b[39m_data_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39m_data_cache\n\u001b[0;32m---> 26\u001b[0m data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masanyarray(img\u001b[39m.\u001b[39;49m_dataobj)\n\u001b[1;32m     27\u001b[0m img\u001b[39m.\u001b[39m_data_cache \u001b[39m=\u001b[39m data\n\u001b[1;32m     28\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nibabel/arrayproxy.py:426\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    406\u001b[0m     \u001b[39m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[1;32m    408\u001b[0m \u001b[39m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_scaled(dtype\u001b[39m=\u001b[39;49mdtype, slicer\u001b[39m=\u001b[39;49m())\n\u001b[1;32m    427\u001b[0m     \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m         arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nibabel/arrayproxy.py:393\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    391\u001b[0m     scl_inter \u001b[39m=\u001b[39m scl_inter\u001b[39m.\u001b[39mastype(use_dtype)\n\u001b[1;32m    392\u001b[0m \u001b[39m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m scaled \u001b[39m=\u001b[39m apply_read_scaling(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_unscaled(slicer\u001b[39m=\u001b[39;49mslicer), scl_slope, scl_inter)\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    395\u001b[0m     scaled \u001b[39m=\u001b[39m scaled\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mpromote_types(scaled\u001b[39m.\u001b[39mdtype, dtype), copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nibabel/arrayproxy.py:363\u001b[0m, in \u001b[0;36mArrayProxy._get_unscaled\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mif\u001b[39;00m canonical_slicers(slicer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape, \u001b[39mFalse\u001b[39;00m) \u001b[39m==\u001b[39m canonical_slicers(\n\u001b[1;32m    360\u001b[0m     (), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    361\u001b[0m ):\n\u001b[1;32m    362\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_fileobj() \u001b[39mas\u001b[39;00m fileobj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 363\u001b[0m         \u001b[39mreturn\u001b[39;00m array_from_file(\n\u001b[1;32m    364\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shape,\n\u001b[1;32m    365\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype,\n\u001b[1;32m    366\u001b[0m             fileobj,\n\u001b[1;32m    367\u001b[0m             offset\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_offset,\n\u001b[1;32m    368\u001b[0m             order\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49morder,\n\u001b[1;32m    369\u001b[0m             mmap\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mmap,\n\u001b[1;32m    370\u001b[0m         )\n\u001b[1;32m    371\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_fileobj() \u001b[39mas\u001b[39;00m fileobj:\n\u001b[1;32m    372\u001b[0m     \u001b[39mreturn\u001b[39;00m fileslice(\n\u001b[1;32m    373\u001b[0m         fileobj,\n\u001b[1;32m    374\u001b[0m         slicer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m         lock\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock,\n\u001b[1;32m    380\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/MultiRatStim/lib/python3.9/site-packages/nibabel/volumeutils.py:453\u001b[0m, in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    451\u001b[0m infile\u001b[39m.\u001b[39mseek(offset)\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(infile, \u001b[39m'\u001b[39m\u001b[39mreadinto\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 453\u001b[0m     data_bytes \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39;49m(n_bytes)\n\u001b[1;32m    454\u001b[0m     n_read \u001b[39m=\u001b[39m infile\u001b[39m.\u001b[39mreadinto(data_bytes)\n\u001b[1;32m    455\u001b[0m     needs_copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # ---------- FIRST LEVEL ANALYSIS ------------\n",
    "\n",
    "df = pd.read_csv(metadata_path, sep='\\t')\n",
    "df = df.loc[(df['exclude'] != 'yes')]\n",
    "\n",
    "for index in range(47, 48):\n",
    "    \n",
    "    #sibmit job to HPC\n",
    "    p1 = subprocess.Popen([\"echo\", f\"{init_folder}\"], stdout=subprocess.PIPE)\n",
    "    subprocess.call([\"qsub\", \"-N\", 'glm', \"-l\", 'nodes=1:ppn=1,mem=12gb,walltime=00:10:00'], stdin=p1.stdout)        #subprocess.call([\"./RABIES_preprocess.sh\", subj_num, TR, correction_arg], shell=False) #run RABIES_preprocess, giving additional inputs: correction_args, specified in metadat_rabies, submit job to qsub\n",
    "\n",
    "    subj_num=str(df.iloc[index]['rat.sub'])[:-2]\n",
    "    print(subj_num)\n",
    "\n",
    "    subject_path = analysis_folder+'/sub-0{}_ses-1/bold_datasink/commonspace_bold/_scan_info_subject_id0{}.session1_split_name_sub-0{}_ses-1_T2w/_run_1/sub-0{}_ses-1_run-1_bold_combined.nii.gz'.format(subj_num, subj_num, subj_num, subj_num)\n",
    "\n",
    "    tr=(df.iloc[index]['func.TR'])\n",
    "    hrf_model = 'spm'\n",
    "    func_img = nib.load(subject_path)\n",
    "    header = func_img.header\n",
    "\n",
    "\n",
    "    dimension = np.array(image.load_img(subject_path).shape)          #put in an array; dimension, number of slices, number of volumes \n",
    "    n_scans = dimension[3]                                            #nb volumes\n",
    "    frame_times = np.arange(n_scans) * tr                             # corresponding frame times\n",
    "\n",
    "    # --- Events regressor --- \n",
    "    \n",
    "    onset = np.matrix(df.iloc[index]['func.sensory.onset']).A[0]\n",
    "    duration = np.matrix(df.iloc[index]['func.sensory.duration']).A[0]\n",
    "    events = pd.DataFrame({'onset': onset,'duration': duration})\n",
    "    events_list = events.append(events)\n",
    "\n",
    "    print(df.iloc[index]['func.sensory.onset'])\n",
    "    \n",
    "    # --- Motion regressors ---\n",
    "\n",
    "    cofounders_file = 'sub-0{}_ses-1_run-1_bold_RAS_combined_confounds.csv'.format(subj_num)\n",
    "    cofounders_path = analysis_folder+'/sub-0{}_ses-1/confounds_datasink/confounds_csv/_scan_info_subject_id0{}.session1_split_name_sub-0{}_ses-1_T2w/_run_1/sub-0{}_ses-1_run-1_bold_combined_confounds.csv'.format(subj_num, subj_num, subj_num, subj_num)\n",
    "\n",
    "    cofounders = pd.read_csv(cofounders_path, sep=',')\n",
    "\n",
    "    motion_names = ['mov1', 'mov2', 'mov3', 'rot1', 'rot2', 'rot3']\n",
    "    motion = np.array(cofounders[motion_names])\n",
    "    \n",
    "    \n",
    "    # --- Compute design matrix --- \n",
    "\n",
    "    design_matrix = make_first_level_design_matrix(frame_times=frame_times, \n",
    "                                                   events=events, \n",
    "                                                   add_regs=motion, \n",
    "                                                   add_reg_names=motion_names, \n",
    "                                                   drift_model=\"polynomial\", \n",
    "                                                   drift_order=3, \n",
    "                                                   hrf_model=hrf_model, \n",
    "                                                   high_pass=0.01)\n",
    "    plot_design_matrix(design_matrix) \n",
    "    savetxt(matrix_dir+'matrix_sub-0{}_ses-1.csv'.format(subj_num), design_matrix, delimiter=',')\n",
    "\n",
    "    # --- Fitting a first-level model --- \n",
    "    \n",
    "    fmri_glm = FirstLevelModel()\n",
    "    fmri_glm = fmri_glm.fit(subject_path, design_matrices=design_matrix)\n",
    "    \n",
    "    # -- Coompute contrasts ---\n",
    "    \n",
    "    n_columns = design_matrix.shape[1]\n",
    "    contrast_val = np.hstack(([1], np.zeros(n_columns - 1)))\n",
    "    print('Contrasts: ', contrast_val)\n",
    "\n",
    "    statistical_map= fmri_glm.compute_contrast(contrast_val, output_type='all')\n",
    "\n",
    "    plotting.plot_stat_map(statistical_map['z_score'], bg_img = template_path, threshold = 1.9, title = 'Test: Rat{}'.format(subj_num))\n",
    "    plt.savefig(image_dir+'stat_map_sub-0{}_ses-1'.format(subj_num)+'.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c5dad12ff72352c6e412781601cff81334509ae240da0f2a4460ea7b76d1faa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
